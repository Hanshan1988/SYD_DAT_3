{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Null accuracy, handling missing values\n",
    "2. Confusion matrix, sensitivity, specificity, setting a threshold\n",
    "3. Handling categorical features, interpreting logistic regression coefficients\n",
    "4. Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Null Accuracy, Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of the Titanic exercise"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 5,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668161434978\n"
     ]
    }
   ],
   "source": [
    "# TASK 1: read the data from titanic.csv into a DataFrame\n",
    "import pandas as pd\n",
    "titanic = pd.read_csv('../../data/titanic.csv', index_col='PassengerId')\n",
    "\n",
    "# TASK 2: define Pclass/Parch as the features and Survived as the response\n",
    "feature_cols = ['Pclass', 'Parch']\n",
    "X = titanic[feature_cols]\n",
    "y = titanic.Survived\n",
    "\n",
    "# TASK 3: split the data into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# TASK 4: fit a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# TASK 5: make predictions on testing set and calculate accuracy\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null accuracy\n",
    "\n",
    "Null accuracy is the accuracy that could be achieved by always predicting the **most frequent class**. It is a baseline against which you may want to measure your classifier."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 6,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42600896861\n",
      "0.57399103139\n"
     ]
    }
   ],
   "source": [
    "# compute null accuracy manually\n",
    "print y_test.mean()\n",
    "print 1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 7,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57399103139\n"
     ]
    }
   ],
   "source": [
    "# equivalent function in scikit-learn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dumb = DummyClassifier(strategy='most_frequent')\n",
    "dumb.fit(X_train, y_train)\n",
    "y_dumb_class = dumb.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_dumb_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "scikit-learn models expect that all values are **numeric** and **hold meaning**. Thus, missing values are not allowed by scikit-learn.\n",
    "\n",
    "One possible strategy is to just **drop missing values**:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 8,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
<<<<<<< HEAD
     "execution_count": 4,
=======
     "execution_count": 8,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 9,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 11)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 9,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with any missing values\n",
    "titanic.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 10,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 11)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 6,
=======
     "execution_count": 10,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows where Age is missing\n",
    "titanic[titanic.Age.notnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a better strategy is to **impute missing values**:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 11,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill missing values for Age with the mean age\n",
    "titanic.Age.fillna(titanic.Age.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 12,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hansh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# equivalent function in scikit-learn, supports mean/median/most_frequent\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(strategy='mean', axis=1)\n",
    "titanic['Age'] = imp.fit_transform(titanic.Age).T"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 13,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67264573991\n"
     ]
    }
   ],
   "source": [
    "# include Age as a feature\n",
    "feature_cols = ['Pclass', 'Parch', 'Age']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 14,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107,  21],\n",
       "       [ 52,  43]])"
      ]
     },
<<<<<<< HEAD
     "execution_count": 12,
=======
     "execution_count": 14,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 15,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45263157894736844"
      ]
     },
<<<<<<< HEAD
     "execution_count": 13,
=======
     "execution_count": 15,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the sensitivity\n",
    "43 / float(52 + 43)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 16,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8359375"
      ]
     },
<<<<<<< HEAD
     "execution_count": 14,
=======
     "execution_count": 16,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the specificity\n",
    "107 / float(107 + 21)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 17,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 18,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<matplotlib.text.Text at 0x1f506160>"
      ]
     },
     "execution_count": 17,
=======
       "<matplotlib.text.Text at 0x10c5434d0>"
      ]
     },
     "execution_count": 18,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
<<<<<<< HEAD
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f277a20>"
=======
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEPCAYAAACgFqixAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk4EkCZOBJAmTgSQJk4EkCZOBJAn4/9pLR3x9AwPNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10af926d0>"
>>>>>>> upstream/master
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the predicted probabilities\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.hist(y_pred_prob)\n",
    "plt.xlabel('Predicted probability of survival')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 37,
=======
   "execution_count": 19,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1\n",
      " 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
      " 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# change the threshold for predicting survived to increase sensitivity\n",
    "import numpy as np\n",
    "y_pred_class = np.where(y_pred_prob > 0.25, 1, 0)\n",
    "print y_pred_class"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 40,
=======
   "execution_count": 20,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "# equivalent function in scikit-learn\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize(y_pred_prob.reshape(-1, 1), 0.25)\n",
    "print y_pred_class"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 21,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57 71]\n",
      " [27 68]]\n"
     ]
    }
   ],
   "source": [
    "# new confusion matrix\n",
    "print metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 22,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715789473684\n"
     ]
    }
   ],
   "source": [
    "# new sensitivity\n",
    "print 68 / float(27 + 68)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 23,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4453125\n"
     ]
    }
   ],
   "source": [
    "# new specificity\n",
    "print 57 / float(57 + 71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Handling Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding\n",
    "\n",
    "**Pclass** is an ordered categorical feature, and is already encoded as 1/2/3, so we leave it as-is.\n",
    "\n",
    "**Sex** is an unordered categorical feature, and needs to be dummy encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy encoding with two levels"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 24,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode Sex_Female feature\n",
    "titanic['Sex_Female'] = titanic.Sex.map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
=======
   "execution_count": 25,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
<<<<<<< HEAD
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
=======
       "          fit_intercept=True, intercept_scaling=1, penalty='l2',\n",
       "          random_state=None, tol=0.0001)"
      ]
     },
     "execution_count": 25,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include Sex_Female in the model\n",
    "feature_cols = ['Pclass', 'Parch', 'Age', 'Sex_Female']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg=LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression coefficients"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 26,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[('Pclass', -1.2209320913215747),\n",
       " ('Parch', -0.11739489079983109),\n",
       " ('Age', -0.040484266337008495),\n",
       " ('Sex_Female', 2.6815252125472218)]"
      ]
     },
     "execution_count": 30,
=======
       "[('Pclass', -1.2209320928750262),\n",
       " ('Parch', -0.1173948910960517),\n",
       " ('Age', -0.040484295054160194),\n",
       " ('Sex_Female', 2.6815252122038973)]"
      ]
     },
     "execution_count": 26,
>>>>>>> upstream/master
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log \\left({p\\over 1-p}\\right) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\beta_4x_4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', 0.29495511365485361),\n",
       " ('Parch', 0.8892339735062349),\n",
       " ('Age', 0.96032427381103702),\n",
       " ('Sex_Female', 14.607355636262817)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to odds\n",
    "zip(feature_cols, np.exp(logreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probability of survival for **Adam**: first class, no parents or kids, 29 years old, male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hansh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.50359593])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba([1, 0, 29, 0])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Pclass coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probability of survival for **Bill**: same as Adam, except second class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hansh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.23031239])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba([2, 0, 29, 0])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we have calculated that change ourselves using the coefficients?\n",
    "\n",
    "$$odds = \\frac {probability} {1 - probability}$$\n",
    "\n",
    "$$probability = \\frac {odds} {1 + odds}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2277992277992278"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Adam's probability to odds\n",
    "adamodds = 0.5/(1 - 0.5)\n",
    "\n",
    "# adjust odds for Bill due to lower class\n",
    "billodds = adamodds * 0.295\n",
    "\n",
    "# convert Bill's odds to probability\n",
    "billodds/(1 + billodds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Sex_Female coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probability of survival for **Susan**: same as Adam, except female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hansh\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.93678482])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba([1, 0, 29, 1])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate that change ourselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9358974358974359"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust odds for Susan due to her sex\n",
    "susanodds = adamodds * 14.6\n",
    "\n",
    "# convert Susan's odds to probability\n",
    "susanodds/(1 + susanodds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the **Sex_Female coefficient**? For a given Pclass/Parch/Age, being female is associated with an increase in the **log-odds of survival** by 2.68 (or an increase in the **odds of survival** by 14.6) as compared to a male, which is called the **baseline level**.\n",
    "\n",
    "What if we had reversed the encoding for Sex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode Sex_Male feature\n",
    "titanic['Sex_Male'] = titanic.Sex.map({'male':1, 'female':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', -1.2201766909129148),\n",
       " ('Parch', -0.11678129630652558),\n",
       " ('Age', -0.040432991181856698),\n",
       " ('Sex_Male', -2.6803869181753894)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include Sex_Male in the model instead of Sex_Female\n",
    "feature_cols = ['Pclass', 'Parch', 'Age', 'Sex_Male']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient is the same, except that it's **negative instead of positive**. As such, your choice of category for the baseline does not matter, all that changes is your **interpretation** of the coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy encoding with more than two levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we include an unordered categorical feature with more than two levels, like **Embarked**? We can't simply encode it as C=1, Q=2, S=3, because that would imply an **ordered relationship** in which Q is somehow \"double\" C and S is somehow \"triple\" C.\n",
    "\n",
    "Instead, we create **additional dummy variables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Embarked_C  Embarked_Q  Embarked_S\n",
       "PassengerId                                    \n",
       "1                     0           0           1\n",
       "2                     1           0           0\n",
       "3                     0           0           1\n",
       "4                     0           0           1\n",
       "5                     0           0           1\n",
       "6                     0           1           0\n",
       "7                     0           0           1\n",
       "8                     0           0           1\n",
       "9                     0           0           1\n",
       "10                    1           0           0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 3 dummy variables\n",
    "pd.get_dummies(titanic.Embarked, prefix='Embarked').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we actually only need **two dummy variables, not three**. Why? Because two dummies captures all of the \"information\" about the Embarked feature, and implicitly defines C as the **baseline level**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Embarked_Q  Embarked_S\n",
       "PassengerId                        \n",
       "1                     0           1\n",
       "2                     0           0\n",
       "3                     0           1\n",
       "4                     0           1\n",
       "5                     0           1\n",
       "6                     1           0\n",
       "7                     0           1\n",
       "8                     0           1\n",
       "9                     0           1\n",
       "10                    0           0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create 3 dummy variables, then exclude the first\n",
    "pd.get_dummies(titanic.Embarked, prefix='Embarked').iloc[:, 1:].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we interpret the encoding:\n",
    "\n",
    "- C is encoded as Embarked_Q=0 and Embarked_S=0\n",
    "- Q is encoded as Embarked_Q=1 and Embarked_S=0\n",
    "- S is encoded as Embarked_Q=0 and Embarked_S=1\n",
    "\n",
    "If this is confusing, think about why we only needed one dummy variable for Sex (Sex_Female), not two dummy variables (Sex_Female and Sex_Male). In general, if you have a categorical feature with **k levels**, you create **k-1 dummy variables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with the two dummy variable columns\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked, prefix='Embarked').iloc[:, 1:]\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame (axis=0 means rows, axis=1 means columns)\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex  Age  \\\n",
       "PassengerId                                                                   \n",
       "1                                      Braund, Mr. Owen Harris    male   22   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38   \n",
       "3                                       Heikkinen, Miss. Laina  female   26   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35   \n",
       "5                                     Allen, Mr. William Henry    male   35   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "PassengerId                                                           \n",
       "1                1      0         A/5 21171   7.2500   NaN        S   \n",
       "2                1      0          PC 17599  71.2833   C85        C   \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "4                1      0            113803  53.1000  C123        S   \n",
       "5                0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "             Sex_Female  Sex_Male  Embarked_Q  Embarked_S  \n",
       "PassengerId                                                \n",
       "1                     0         1           0           1  \n",
       "2                     1         0           0           0  \n",
       "3                     1         0           0           1  \n",
       "4                     1         0           0           1  \n",
       "5                     0         1           0           1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', -1.1884986221351446),\n",
       " ('Parch', -0.093622382178363953),\n",
       " ('Age', -0.040727315628766678),\n",
       " ('Sex_Female', 2.6425065647714199),\n",
       " ('Embarked_Q', -0.18494075926983072),\n",
       " ('Embarked_S', -0.61019906884956532)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include Embarked_Q and Embarked_S in the model\n",
    "feature_cols = ['Pclass', 'Parch', 'Age', 'Sex_Female', 'Embarked_Q', 'Embarked_S']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg=LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77777778  0.8         0.7752809   0.86516854  0.7752809   0.7752809\n",
      "  0.78651685  0.7752809   0.80898876  0.81818182]\n",
      "0.795775734877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Evaluate each stage of the model with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols_list = [['Pclass', 'Parch'], ['Pclass', 'Parch', 'Age'], ['Pclass', 'Parch', 'Age', 'Sex_Female'],\n",
    "                     ['Pclass', 'Parch', 'Age', 'Sex_Female', 'Embarked_Q', 'Embarked_S']]\n",
    "scores_n = []\n",
    "scores_n_mean = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for feature_cols in feature_cols_list:\n",
    "    X = titanic[feature_cols]\n",
    "    scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "    scores_n.append(scores)\n",
    "    scores_n_mean.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Pclass', 'Parch'], 0.69049341731926017),\n",
       " (['Pclass', 'Parch', 'Age'], 0.70276472591079331),\n",
       " (['Pclass', 'Parch', 'Age', 'Sex_Female'], 0.79009391669504025),\n",
       " (['Pclass', 'Parch', 'Age', 'Sex_Female', 'Embarked_Q', 'Embarked_S'],\n",
       "  0.79577573487685849)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(feature_cols_list, scores_n_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Evaluate the Cross-Validation score with different values of n (2, 5, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_n = []\n",
    "scores_n_mean = []\n",
    "n_list = [2, 5, 10, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for n in n_list:\n",
    "    scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=n)\n",
    "    scores_n.append(scores)\n",
    "    scores_n_mean.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.69049341731926017),\n",
       " (5, 0.70276472591079331),\n",
       " (10, 0.79009391669504025),\n",
       " (50, 0.79577573487685849)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(n_list, scores_n_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
